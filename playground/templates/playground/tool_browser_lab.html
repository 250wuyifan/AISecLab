{% extends "base.html" %}
{% block extra_css %}
<style>
.lab-sidebar-list .nav-link.active { background-color: rgba(13,110,253,0.12); border-radius: 0.375rem; color: var(--primary-color); font-weight: 600; }
.iframe-wrap { border: 1px solid #e2e8f0; border-radius: 4px; overflow: hidden; height: 360px; background: #f8fafc; }
html[data-theme="dark"] .iframe-wrap { border-color: #334155; background: #1e293b; }
</style>
{% endblock %}
{% block content %}
<main class="lab-detail-main"><div class="container py-4">
    <!-- 返回按钮 -->
    <div class="mb-3">
        <a href="{% url 'playground:lab_list' %}" class="btn btn-outline-secondary btn-sm lab-back-btn">
            <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="me-1">
                <polyline points="15 18 9 12 15 6"></polyline>
            </svg>
            返回靶场列表
        </a>
    </div>

    <!-- 靶场工具栏 -->
    {% include "playground/_lab_tools.html" with lab_slug="tool_security:browser" %}

    <div class="d-flex justify-content-between align-items-center mb-4">
        <div>
            <h3 class="mb-1">Tool·浏览器操作</h3>
            <div class="text-muted small">用户指令经 LLM 输出「要打开的 URL」→ Agent 代用户打开；Prompt Injection 可让 LLM 输出恶意/内网 URL → CSRF/SSRF/N-day。</div>
        </div>
        <div class="text-end">
            <span class="small text-muted">当前模型：<span class="fw-semibold">{{ current_model|default:"未配置" }}</span></span>
            <button type="button" class="btn btn-sm btn-outline-secondary ms-2" data-bs-toggle="modal" data-bs-target="#llmConfigModal">靶场配置</button>
        </div>
    </div>
    {% if not has_llm_config %}
    <div class="alert alert-warning">尚未配置或启用大模型，请点击「靶场配置」。</div>
    {% endif %}
    <div class="card shadow-sm mb-4">
        <div class="card-body">
            <h5 class="card-title mb-2">演练步骤</h5>
            <ol class="small text-muted mb-2">
                <li>下方输入<strong>用户指令</strong>（如「打开 https://example.com 看看」）；LLM 输出 URL，本页在 iframe 中打开该 URL；</li>
                <li>体会：若 Agent 被控，攻击者可通过注入让 LLM 输出恶意/内网 URL → Agent 代用户访问。</li>
            </ol>
        </div>
    </div>
    <div class="card shadow-sm mb-4">
        <div class="card-body">
            <h5 class="card-title mb-2">用户指令（LLM 将输出要打开的 URL）</h5>
            <input type="text" class="form-control font-monospace mb-2" id="tool-browser-message" placeholder="例如：打开 https://example.com 看看" value="打开 https://example.com 看看">
            <button type="button" class="btn btn-danger" id="tool-browser-go">模拟 Agent 打开（LLM → iframe）</button>
            <div class="mt-3"><strong>加载结果（iframe 模拟）：</strong></div>
            <div class="iframe-wrap mt-2">
                <iframe id="tool-browser-frame" src="about:blank" title="模拟 Agent 打开的页面" style="width:100%;height:100%;border:0;"></iframe>
            </div>
        </div>
    </div>
    <div class="card shadow-sm"><div class="card-header"><strong>怎么修复</strong></div>
        <div class="card-body small"><ul class="mb-0"><li>URL 白名单；禁止内网、file://、data:；浏览器沙箱（headless + 最小权限）；及时修补 N-day。</li></ul></div>
    </div>
</div></main>
{% include "playground/_tool_lab_llm_config_modal.html" %}
<script>
(function(){
    var msgEl=document.getElementById('tool-browser-message'); var frame=document.getElementById('tool-browser-frame'); var btn=document.getElementById('tool-browser-go');
    var apiUrl='{% url "playground:tool_browser_url_api" %}';
    if(btn&&msgEl&&frame) btn.addEventListener('click',function(){
        var m=(msgEl.value||'').trim(); if(!m){ return; }
        fetch(apiUrl,{ method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({message:m}) })
        .then(function(r){ return r.json(); }).then(function(d){
            var u=(d.url||'').trim();
            if(u) try{ frame.src=u; }catch(e){ frame.src='about:blank'; }
        });
    });
})();
</script>
{% endblock %}
